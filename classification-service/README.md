# classification-service

Determine whether a given prompt is suitable for generating an image, categorizing it as either safe for work (SFW) or not safe for work (NSFW).
The classification uses the model [eliasalbouzidi/distilbert-nsfw-text-classifier](https://huggingface.co/eliasalbouzidi/distilbert-nsfw-text-classifier).

The current code runs in CPU-only mode.
